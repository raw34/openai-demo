# openai-demo

[
"how to train loras and models for amazing results hello my friends how are you doing a lot of people get bad results with their training but actually it 's super easy to get good results so today I 'm gon na show you why it works how it works I will show you the best tools and also my merging trick to get even better results let 's get started so one of the biggest things is to get help I have a specific Channel inside of my Discord for Laura and model training check that out there 's a lot of very interesting helpful people in there I'm often in there too this is the address I 'm also linked it below the video now here 's the next step and that is to understand how does the process actually work because this makes you understand what kind of images to select for them and how the Laura or the model actually understands your images so what you can see here is on the left side we have the input photo now this photo is basically dissolved into Noise by that learning process the noise is actually the seed number that you are using when you create an AI image now in the Training Method this is then trying to desolve that noise again into an image of course the image is going to be different from the input image but the training tries to get them as close as possible so you can see here I want to train photography with neon lights in the background so this is my input and I 'm getting some very nice output from that too of course another thing you can also understand from that is now the size of objects in your image especially faces and this is what a lot of people have problems with and even lauras and models you can download from online Pages like cvd I have problems with that so of course as you can see here when I have a face that is small in the image this is only also occupying a small part of the noise so of course when I want to reconstruct that into an actual image I ca n't do that from that little part of noise to a bigger part of that image this is why you also need bigger face images so you are able to actually create close-ups but also smaller face images so you're actually able to create half portraits or even full body Images so when we come here to the next step of course the question is what kind of images do we need to select so for example if you want to train on a person what you want to have here is for example different emotions different phase Expressions so that the AI can learn what the face looks like in these different Expressions another thing is different kind of fashion styles that you want to use so that the AI also can learn how the fashion looks on that person if you are able to have images in different hairstyles that 's also a benefit because this can help you to show that face in these hairstyles but also show how the hair of that person naturally Falls then of course head rotations the more you have the better also maybe from strange angles is good so you can afterwards have more complex images and the AI understands how that face looks from all kinds of different directions lighting situations are also good so try to have the model in different like Bright Lights complex lights dark lights overcast rainy days all these kind of situations so again the AI can learn how the model and the face looks in these light situations and then of course different kind of body captures the full body half of the body a close-up with only the upper body the face close up things like that so again first of all the AI can learn how that model looks in these different shots then also the AI can learn from that how how the body of the model actually looks and then thirdly of course we can train the body in different sizes inside of the noise so everything can come together afterwards and can work with many of your prompts next of course the question is here the image quality so I would suggest you try to use higher resolution images but more importantly you want to have high quality images that are not blurry that are not pixelated that don't have compression fragments in them it does n't have to be that high resolution as I show it in this image here the main point here is that everything in the image is sharp and easy to Define by the AI because as I said the image is going to be dissolved into noise so it is really important that for example the eyelashes can split up into these individual pixels in the noise and not cover up larger area of that so for example here we have a bad image and you can see when we zoom into the eye this is just a blurry mess the image might look good to you on the screen but for the AI this is just a muddy mess where the AI ca n't figure out the actual details it 's kind of hard to see here what is Shadow what is here what is a wrinkle so good image quality will create good results another thing here that is really important to understand is the keywords that you 're using in the text files now the way these keywords work is they are variables so for example if you would describe every hair as hair the AI could n't learn the difference between the", "different hair styles hair lengths hair colors so if you want to have a variability in there if you want to be able to change that and the AI can react to the change you need to put that into the key keyword so for example here we have neon light but also orange light so we are able to change the light color later on we have curly hair dark hair short hair so that we understand in a different image it might not be curly hair because it looks different and the eye can understand it from your keywords and then later on when it is reconstructing noise into an image it knows how to move the noise around how to combine the noise to create for example a green sweater with short sleeves so at that point the big question is what should we train should we go with a Laura or should we go with a model what is the difference well basically allora is a smaller version of a model but you can also apply it to other models so it 's kind of an add-on to other models this is also the benefit here allora can be used on many models and the cool thing in here is even though for example you have trained a Laura on photos you can still afterwards use that Laura on digital painting models or anime models and it will try to reconstruct the facial structure in the style of the checkpoint another benefit for Laura is also that you can use multiple loras in the same prompt so for example you can train the face of a person and then you can have independently a Laura that is for example is trained on a certain style of clothing of course allora is also smaller because it 's not a full model it 's not a full checkpoint so you can store a lot more loras on your drive than you can store models and because loras are an add-on they are really great for faces because then afterwards you can use that phase in all kinds of different models all kinds of different styles now when we talk about a model that is a full checkpoint these are large files multiple gigabytes in size but personally I found that they are more consistent in what you want to train so they are a little bit easier to handle they are more forgiving but also the good thing here is you can merge fix them which means that you merge them with another model that already has parts of what you want to achieve and that will fix the problems that your model has so it does n't have to be a hundred percent perfectly trained and it will still work personally I think because models are easier to train more for giving they are great for themes like architecture in this case but of course if you want to apply these themes or Styles onto other models a Laura would be better in that case personally I would suggest to you when you're getting started train on the images of a star now that sounds a little bit controversial but this is just for private research purpose now one of the main reasons why I suggest this is because for stars we have a lot of images out there in all kinds of face expressions clothings light Styles all kinds of images so that is very easy to find and for private use for your own research for your own training it 's also in most countries legal to use these images because it 's private use another thing that makes this great for beginners is that for you it is really easy to spot problems because you know what the star looks like even in different situations because you 've seen them in shows a lot also for you it is easier to test different keywords and different situations so with that prompt because you can still figure out does this actually match how I feel that this star is looking for example in a full body shot or with different kinds of clothings with different kind of light situations with different kind of face expressions that 's the Laura or the model hold up because you know that face so well so for you that is easy to understand and because of that is easy to identify problems and you can improve the selection of your image the keywords you 're writing the training process on how many steps you use how many epochs you use and so on so this is actually a very good way because it 's easy to control now another question is here how many images do you actually need the thing here is if you have a complex subject like for example an architectural style or an artistic style something that changes with every image something that does n't have a finite defined form like for example a phase test you need more images so that the AI can understand from these examples and also you create more situations for the training for the AI to understand and that means you should use more images for that now if you 're training a face the face is not changing that much of course it has different kinds of face expressions but it 's basically always the same phase so you can get away with a lot less images especially if they are high quality images so for a face you might be okay with as little as just 15 images one thing you will often read about with the training of loras and models or steps in epochs but what are they well steps or as they sometimes all", "go so-called are repetitions is how many steps in the render process in the training process are used per image then the epochs are basically when you create a copy of that model if you want to have a safe copy or when in the training it is going to the Next Generation basically of that model for a Laura or for a checkpoint now here that means that you basically can iterate you can improve on the first checkpoint so usually you 're using 10 epochs so when the first Epoch is finished can be used as a training partner to improve towards the next Epoch but what that also means is if you have a total of a Thousand Steps it is not the same thing to use just one Epoch that has a thousand steps or if you use 10 epochs that have a hundred steps each and it 's actually better to have these 10 epochs with 100 steps that of course is just a number example to make the numbers easier the next question is of course how many steps an Epoch should be used well there is actually not a fixed value that you can just use for everything so you have to do a lot of training to see what you get and if it works for what you want to achieve but there is still some guidance you can use so if you have a lot of images let 's say you have 100 rate of 200 300 images you 're going to use less steps per image but you want to use at least 10 steps per image on the other hand the other way around if you have very few images of that subject you want to use more steps for that you can for example also use a hundred steps per image to train each image really deeply now like I said in the beginning when you have for example a face you can get away with both not having much images and also using lower step numbers so 15 images with 10 steps each on 10 epochs that might already be enough to train a face while on the other hand of course if you have a more complex subject you often need more images and then also more steps on that to actually train that the good thing here with the Laura is it does n't use usually as many steps as a model does so often you can get away with between one thousand five hundred and six thousand steps for your Laura on the model you often use a lot more steps for that so it is n't rare to use 30 000 or more steps for your checkpoint model training but of course I 'm going to show you a merge trick where you can get away with less steps which means the model is n't fully trained but you 're gon na improve the quality by mixing it with a better model and of course we also have the question of image size now you should have a minimum size of 512 by 512 bigger images are actually better because they give the AI more quality and more things to train with in the past people suggested to crop these images to a square ratio but I would personally no longer suggest that because in most images you will crop out the things you actually want to train so I 'm using uncropped images and actually the training processes automatically creating buckets for you with these different ratios so you can for example see here different render buckets that are prepared by the software and what this does is that the software tries to figure out the best resolution and ratio for the images you 're using putting that into different buckets and then training these different resolutions and this also gives you the benefit that then afterwards when you 're using different resolutions the images will look really good and I want you to keep in mind that for example if you do the upscaling as I suggested with image to image that also means that a model is trained on high resolutions and will give you really good quality when you upscale it to double the size in image to image which it ca n't do if it is only trained on small resolution and images but of course one thing I need to point out here is that higher resolution images will make the training process slower and of course this has to do with your GPU power if you want to see a video on how to train these models with online services so you are not reliant on your own Hardware write that in the comment and I will create a video like that so let 's have a look at the tools here now of course first I want to show you how to find the images now if you do the training on a star portrait what you can do is of course use Google Images but after entering the name up here what you also want to do is here 's a button for tools click on that and then you can see here size and you can select large and this will then only show you the large images now like I said it is good to have images of all kinds of different ratios all kinds of different sizes of the head different light situations different face expressions different clothing styles and you will find a lot of them for a star so this is very easy to train again you still want to have good image quality so check each image if they are blurry if they are low quality if they have any kind of compression fragments in there or stuff like that another tool that I want to suggest to you is bug resize this is a free tool you can upload your images here for example let 's", "select this image then you want to click here on longest side and you want to enter here a value that is good for you depending on how good your GPU is I often use here 1600 pixels but of course you can go smaller for the image quality I would set this to a hundred percent jpeg format and then stick and then click here on start this will bulk resize all of your images and you can download it as a zip file and then unpack that now next let 's have a look at the folder structure what I want to suggest to you here is that you have a folder that is named after the project in this case I 'm calling it neon in there you you want to have four different folders one is called images and then you also have a log folder a model folder and a source folder the source folder is for the source images you have downloaded from the internet I would save them separately so that you can always go back to these original images if you have to train that model in a different resolution or do other changes to these images these images you download from the internet often can have very long and complex names that might not be a problem but it might be a problem so what I want to suggest to you here is that you select all of these images and then on Windows on your keyboard press f2 now when you have that you can enter a name and this name will be applied to all of the images and then in round brackets you have a number per image giving you a very short file name so next let 's have a look at the software we 're using for training the models and this is going to be Koya SS this is is still one of the easiest tools to use and also has a huge Community when you scroll down until you see Windows you can see that this is actually very easy to install so before you start to install Koya SS what you want to install on your drive unless you already have it on there is python 3.10 3.10 6 3.10 9 is all good next you want to install git for Windows and after that Visual Studio for Windows also below that you 're going to find a command for the terminal window now when you Mouse over that you have your copy button so click on that next you're going to make a folder on your hard drive or you want to put the Koya install and when you have created that folder go into that folder and click up here in the address bar write CMD and hit enter this is going to open the terminal now on your keyboard press Ctrl V to put in that command to be copied from the page and he is giving you a warning if you really want to have this multi-line command simply approve that and this is going to start the process in the first step this is starting to download the Koya repo for you in the next step this should automatically start the setup for you if this is not happening you want to go into the Koya SS folder where all of these files have been downloaded and if you want to manually double click on the setup.bed file when this is opening up this is asking you a series of questions now the first one is if you want to uninstall previous versions of torch and you want to say no to that which is the selection too in The Next Step this is asking you if you want to use torch version 1.1 or torch version 2. you should absolutely choose version 2 because this can highly speed up your training process in case this did not work for you in the training because still it says your expert are mental you can simply delete the Koya folder and repeat all of the install with version 1.12 at the end of the installation process this will also ask you a series of questions now the right choices are always highlighted for you so choose these choices really easy to go through that process when that is finished don't close that window yet because another important thing here to get that speed pump if you have a Nvidia card of the 30 or 40 generation is to install c-u-d-n-n 8.6 you want to click on the link here and this will download a zip file for you unpack the zip file and in there is a CU ddn Windows folder you want to drag that folder directly into the install directory of your Koya SS after that you 're going back to the still open install window and you want to copy this command here so again hover over it on the right side you have the copy button go into the command window and copy this in there to activate that script or in case you have already closed that window simply go back to your Koya SS folder click up here in the address bar write CMD and then you want to copy that command in here and let it run through after all this is done we have to do a last step and that is to run our upgrade PS1 so for that you right click on that file and you select run with Powershell this will download the latest version of all of your files after all this is done you have here a GUI user.pad you want to double click on that this will then start for you the Korea software and also open up the browser window for you in case it did n't open up the browser window for you here is the local IP address that you can put into your browser to load the web UI of this tool now when you 're in here you will see a interface that is", "very similar to automatic 1111 from the design and on the top you will find that you have a tab here for dreambooth this is for your checkpoint model training then you have dream boost Laura training and next to that you also have dream Booth textual inversion training now today we 're gon na go over the first two at the end you also have fine tuning here which I will talk about in a later video and you have utilities this is what we are going to use next now one of the most important things in here is the captioning of your image files this means that the AI will automatically create keyword text files for you in most cases it is suggested to use the wd14 captioning tool so for that you want to select this tab here now you click on this button to select the browser where your images are but first of course where are these images we have made a project folder for our training in this case it is called neon and I have here an images folder but the images are not in the images folder because inside of there is another folder and this is called 20 or the number of steps you want to use per image for training underscore and then neon as the project name so that means for you you click here on this folder button and then you go to your project folder to the image folder and in there you select this folder with the number and the project name and you select that folder then in this case you do n't have to do any kind of other settings here and simply click down here on captioning images now when you first do that that may take a while it might download here a captioning model first now as I've shown you for each of these images you have a text file that has the same name as the image when you open this up you will see in here all the captioning keywords that the AI has found to describe your image now they might not always be the right words for that image so you want to check that on these images to make that process a lot easier I have a really good tool for you it's called boru data set tag manager when you are on the GitHub side of this I've linked that below of course here on the right side you see a link for releases so you click on that and you 're coming to this page here below here you see one file that 's called all included zip so you want to download and unpack that zip you can put that zip file anywhere on your hard drive I would suggest to put it into the documents folder when you open that up in here is a lot of different files but one of them is called the borrow data settag manager.exe and this is going to load this software for you now you want to load the folder so you go to file load folder and you go to the folder where your images and the text files are and select that folder now what is happening here is on the left side you see all the images in the middle you see the keywords for that specific image you have selected and on the right side you see all of the text from all of the images also when you go up here to view you can select Show preview that is very useful you want to resize that to make it smaller because this will then always show you a preview of the image that you have selected so you can actually go through the images and the preview is loading for you you can also make that a little bit bigger and then you can compare the image with the keywords now for example if you want to have keywords that are in all of the images the same on the right side here was the General list you have here different signs that allow you to delete keywords or to add keywords to add keywords you click on the green plus you can hear write the tag that you want to enter that can be one or multiple words and you can select on what position this should be in the list of your keyboard words now as I've shown you at the beginning of the video it is important here on how you set these keywords so think about what do you want to change in the image afterwards so for example here we have a haircut and this is short hair so if you want to have long hair afterwards you might want to Define this as short here also she 's wearing glasses if you want to be able to switch this between reading classes sunglasses or other kinds of classes you want to Define these for example as a reading glasses so with the keywords there 's a lot of experimentation there 's a lot of refining that you can do that actually helps you get a better model for the beginning you want to train for example a character with less photos so it does n't take too much time to experiment with these keywords and see what kind of results you get this brings us back to the training of a star portrait after you 're finished with all of your changes you want to click here on file and say if all changes next we also need a model that we want to train on so for that it 's a good idea to use the stable diffusion 1.5 model I have linked this page below and you can see here that you have a version 1.5 to prune save tensor this is a pretty big file but it is the file that is used for training compared to the EMA only file that is used for rendering images with a prompt for example so", "you want to download this file anywhere on the disk it doesn't have to be in the Koya folder you can also put it for example in your automatic 1111 folder at this point we are basically ready to go with our render so what you want to do here is you want to click here on selecting the model you want to use so I 'm inside of my automatic 1111 folder in the models folder in the stable diffusion folder you can see I have here my version 1.5 prune safe tensor file so I sell select that and click on open so now I have this model as my source model for the training next we 're going to define the folders here for the image folder click on this icon here then you 're going into your project folder for the training again for me this is called neon and select the images folder then you do the same thing for the model folder and for the lock folder also you want to put down here a name for your model in my case I call it Ollie underscore neon next we 're going to set the training parameters now here you can first set the training batch size this means how many images are trained at the same time this is dependent on multiple factors how fast is your GPU how much vram do you have and also how large is the resolution of the images but also you might want to try to leave this as one because even though this will take a longer time to render it also gives a better result because the AI can spend more time on training on each image for the epoch here you usually want to set this to 10 epochs and then you want to set save every n Epoch to one that means that it makes a copy of each of these epochs if you want to save on your drive space you can also set this to two or three which means that it will only save every second or third Epoch of this model the good thing here is that if you train the model too much you can still try out the other epochs and see if they work better for you I found that for the other settings you can leave them as they are down here you have max resolution I would always set that to 768 by 768 even if you 're rendering for a 1.5 model because that gives you a higher quality and then the only thing you have to do last is to click here on train model and wait for the process to go through now when you click on that this is going here to prepare all of your files show all of the information load all of the images it might be here that you are seeing errors that you're running out of vram if you have that you probably have set a too high train batch size so you want to lower that if you are on training batch size 1 you usually should n't have a problem if you still have a problem you might want to try to lower the image resolution like I said the minimum is 512 by 512. after that all you can do is just wait for this process to finish once the process has finished you again go into your projects folder now into the models folder and in here you see the safe copies of all of your epochs and the one that doesn't have a number this is the last one in here you can see in this case because I have trained a model this one has 5.4 gigabytes so it 's pretty large right click and copy then you go to your automatic 1111 folder to the models folder to the stable diffusion folder and then you want to paste this in here now here is my merging trick because I did n't want to spend too many steps and I also did n't want to spend too much time on keywording my images on captioning the images you can see that after the training even though the training took a considerable time the result is n't great at all and it 's also not responsive to my keywords but I can still fix that because after all what I can see here is that I still get something that looks somewhat like a photo and I get these neon colors here and graffiti in the background so to fix that problem I 'm going here to checkpoint merger in automatic 11 11. here as my primary model I 'm selecting the model that I have trained and in the secondary model I select a model that I want to have as the style in this case I want to have something that is photographic and realistic so I'm selecting realistic Vision version 2. now down for the multiplier you can leave the name here empty because then this will fill it out with the ratio that you have created and down for the multiplier you want to experiment 0.3 is good but if your model is very unresponsive and also creates rather bad results you might want to try to set this to 0.5 which means that the resulting model is half what you have trained in half realistic vision for the checkpoint format you can either choose here ckpt or save tensor and then you simply click on merge so when unloading this merged model you can see that I'm getting exactly what I want to have and you can also see when I upscale this with my image to image method I'm getting a fantastic quality thanks to realistic Vision but in the style that I want to have for my model join my Discord if you want to get more help and leave a like if you enjoyed this video thanks for watching bye oh you 're still here so uh This is the End screen there 's other stuff you can watch like this or", "that 's really cool and yeah I hope I see you soon leave a like if you have n't yet and well um yeah"]

